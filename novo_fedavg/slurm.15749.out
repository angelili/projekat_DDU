Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.012
[1,   200] loss: 0.006
[1,   300] loss: 0.007
[2,   100] loss: 0.006
[2,   200] loss: 0.007
[2,   300] loss: 0.006
[3,   100] loss: 0.004
[3,   200] loss: 0.004
[3,   300] loss: 0.005
[4,   100] loss: 0.004
[4,   200] loss: 0.006
[4,   300] loss: 0.004
[5,   100] loss: 0.004
[5,   200] loss: 0.004
[5,   300] loss: 0.004
[6,   100] loss: 0.003
[6,   200] loss: 0.004
[6,   300] loss: 0.004
[7,   100] loss: 0.004
[7,   200] loss: 0.003
[7,   300] loss: 0.004
[8,   100] loss: 0.004
[8,   200] loss: 0.004
[8,   300] loss: 0.003
[9,   100] loss: 0.003
[9,   200] loss: 0.003
[9,   300] loss: 0.003
[10,   100] loss: 0.003
[10,   200] loss: 0.003
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.013
[1,   200] loss: 0.006
[1,   300] loss: 0.007
[2,   100] loss: 0.005
[2,   200] loss: 0.004
[2,   300] loss: 0.006
[3,   100] loss: 0.003
[3,   200] loss: 0.004
[3,   300] loss: 0.007
[4,   100] loss: 0.005
[4,   200] loss: 0.004
[4,   300] loss: 0.004
[5,   100] loss: 0.003
[5,   200] loss: 0.003
[5,   300] loss: 0.004
[6,   100] loss: 0.003
[6,   200] loss: 0.004
[6,   300] loss: 0.003
[7,   100] loss: 0.003
[7,   200] loss: 0.003
[7,   300] loss: 0.003
[8,   100] loss: 0.003
[8,   200] loss: 0.003
[8,   300] loss: 0.002
[9,   100] loss: 0.003
[9,   200] loss: 0.003
[9,   300] loss: 0.003
[10,   100] loss: 0.003
[10,   200] loss: 0.003
[10,   300] loss: 0.003
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.024
[1,   200] loss: 0.005
[1,   300] loss: 0.006
[2,   100] loss: 0.005
[2,   200] loss: 0.005
[2,   300] loss: 0.003
[3,   100] loss: 0.004
[3,   200] loss: 0.006
[3,   300] loss: 0.004
[4,   100] loss: 0.003
[4,   200] loss: 0.004
[4,   300] loss: 0.003
[5,   100] loss: 0.003
[5,   200] loss: 0.004
[5,   300] loss: 0.003
[6,   100] loss: 0.003
[6,   200] loss: 0.004
[6,   300] loss: 0.003
[7,   100] loss: 0.003
[7,   200] loss: 0.004
[7,   300] loss: 0.003
[8,   100] loss: 0.003
[8,   200] loss: 0.003
[8,   300] loss: 0.003
[9,   100] loss: 0.003
[9,   200] loss: 0.003
[9,   300] loss: 0.003
[10,   100] loss: 0.003
[10,   200] loss: 0.002
[10,   300] loss: 0.003
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.033
[1,   200] loss: 0.005
[1,   300] loss: 0.006
[2,   100] loss: 0.005
[2,   200] loss: 0.005
[2,   300] loss: 0.004
[3,   100] loss: 0.004
[3,   200] loss: 0.003
[3,   300] loss: 0.004
[4,   100] loss: 0.005
[4,   200] loss: 0.002
[4,   300] loss: 0.004
[5,   100] loss: 0.002
[5,   200] loss: 0.003
[5,   300] loss: 0.004
[6,   100] loss: 0.002
[6,   200] loss: 0.004
[6,   300] loss: 0.003
[7,   100] loss: 0.002
[7,   200] loss: 0.004
[7,   300] loss: 0.003
[8,   100] loss: 0.003
[8,   200] loss: 0.003
[8,   300] loss: 0.002
[9,   100] loss: 0.003
[9,   200] loss: 0.004
[9,   300] loss: 0.003
[10,   100] loss: 0.004
[10,   200] loss: 0.003
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.042
[1,   200] loss: 0.005
[1,   300] loss: 0.005
[2,   100] loss: 0.004
[2,   200] loss: 0.003
[2,   300] loss: 0.004
[3,   100] loss: 0.004
[3,   200] loss: 0.004
[3,   300] loss: 0.002
[4,   100] loss: 0.004
[4,   200] loss: 0.004
[4,   300] loss: 0.003
[5,   100] loss: 0.003
[5,   200] loss: 0.003
[5,   300] loss: 0.003
[6,   100] loss: 0.003
[6,   200] loss: 0.003
[6,   300] loss: 0.003
[7,   100] loss: 0.003
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.002
[8,   200] loss: 0.003
[8,   300] loss: 0.003
[9,   100] loss: 0.002
[9,   200] loss: 0.003
[9,   300] loss: 0.002
[10,   100] loss: 0.002
[10,   200] loss: 0.002
[10,   300] loss: 0.003
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.083
[1,   200] loss: 0.004
[1,   300] loss: 0.004
[2,   100] loss: 0.004
[2,   200] loss: 0.004
[2,   300] loss: 0.003
[3,   100] loss: 0.003
[3,   200] loss: 0.003
[3,   300] loss: 0.003
[4,   100] loss: 0.003
[4,   200] loss: 0.003
[4,   300] loss: 0.002
[5,   100] loss: 0.003
[5,   200] loss: 0.003
[5,   300] loss: 0.003
[6,   100] loss: 0.003
[6,   200] loss: 0.003
[6,   300] loss: 0.004
[7,   100] loss: 0.003
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.002
[8,   200] loss: 0.002
[8,   300] loss: 0.002
[9,   100] loss: 0.002
[9,   200] loss: 0.002
[9,   300] loss: 0.003
[10,   100] loss: 0.002
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.117
[1,   200] loss: 0.018
[1,   300] loss: 0.004
[2,   100] loss: 0.004
[2,   200] loss: 0.003
[2,   300] loss: 0.003
[3,   100] loss: 0.003
[3,   200] loss: 0.004
[3,   300] loss: 0.003
[4,   100] loss: 0.004
[4,   200] loss: 0.003
[4,   300] loss: 0.003
[5,   100] loss: 0.003
[5,   200] loss: 0.002
[5,   300] loss: 0.003
[6,   100] loss: 0.003
[6,   200] loss: 0.002
[6,   300] loss: 0.003
[7,   100] loss: 0.004
[7,   200] loss: 0.002
[7,   300] loss: 0.003
[8,   100] loss: 0.006
[8,   200] loss: 0.003
[8,   300] loss: 0.004
[9,   100] loss: 0.003
[9,   200] loss: 0.002
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.002
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.094
[1,   200] loss: 0.005
[1,   300] loss: 0.004
[2,   100] loss: 0.003
[2,   200] loss: 0.003
[2,   300] loss: 0.003
[3,   100] loss: 0.003
[3,   200] loss: 0.003
[3,   300] loss: 0.003
[4,   100] loss: 0.002
[4,   200] loss: 0.002
[4,   300] loss: 0.003
[5,   100] loss: 0.002
[5,   200] loss: 0.002
[5,   300] loss: 0.003
[6,   100] loss: 0.002
[6,   200] loss: 0.003
[6,   300] loss: 0.002
[7,   100] loss: 0.003
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.002
[8,   200] loss: 0.003
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.002
[9,   300] loss: 0.002
[10,   100] loss: 0.003
[10,   200] loss: 0.003
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.081
[1,   200] loss: 0.005
[1,   300] loss: 0.005
[2,   100] loss: 0.003
[2,   200] loss: 0.002
[2,   300] loss: 0.003
[3,   100] loss: 0.002
[3,   200] loss: 0.002
[3,   300] loss: 0.002
[4,   100] loss: 0.002
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.003
[5,   200] loss: 0.003
[5,   300] loss: 0.002
[6,   100] loss: 0.002
[6,   200] loss: 0.004
[6,   300] loss: 0.004
[7,   100] loss: 0.002
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.004
[8,   200] loss: 0.003
[8,   300] loss: 0.003
[9,   100] loss: 0.002
[9,   200] loss: 0.002
[9,   300] loss: 0.001
[10,   100] loss: 0.002
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.078
[1,   200] loss: 0.003
[1,   300] loss: 0.003
[2,   100] loss: 0.003
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.002
[3,   200] loss: 0.003
[3,   300] loss: 0.002
[4,   100] loss: 0.004
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.003
[5,   200] loss: 0.003
[5,   300] loss: 0.002
[6,   100] loss: 0.002
[6,   200] loss: 0.002
[6,   300] loss: 0.002
[7,   100] loss: 0.002
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.001
[8,   200] loss: 0.002
[8,   300] loss: 0.002
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.002
[10,   100] loss: 0.003
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.125
[1,   200] loss: 0.006
[1,   300] loss: 0.003
[2,   100] loss: 0.003
[2,   200] loss: 0.004
[2,   300] loss: 0.002
[3,   100] loss: 0.003
[3,   200] loss: 0.002
[3,   300] loss: 0.002
[4,   100] loss: 0.003
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.001
[6,   200] loss: 0.002
[6,   300] loss: 0.002
[7,   100] loss: 0.002
[7,   200] loss: 0.002
[7,   300] loss: 0.001
[8,   100] loss: 0.002
[8,   200] loss: 0.002
[8,   300] loss: 0.002
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.096
[1,   200] loss: 0.004
[1,   300] loss: 0.003
[2,   100] loss: 0.003
[2,   200] loss: 0.002
[2,   300] loss: 0.003
[3,   100] loss: 0.003
[3,   200] loss: 0.002
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.002
[6,   200] loss: 0.002
[6,   300] loss: 0.001
[7,   100] loss: 0.003
[7,   200] loss: 0.002
[7,   300] loss: 0.002
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.003
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.002
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.086
[1,   200] loss: 0.005
[1,   300] loss: 0.003
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.002
[3,   200] loss: 0.002
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.002
[5,   200] loss: 0.002
[5,   300] loss: 0.002
[6,   100] loss: 0.006
[6,   200] loss: 0.002
[6,   300] loss: 0.002
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.002
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.002
[9,   300] loss: 0.001
[10,   100] loss: 0.002
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.085
[1,   200] loss: 0.005
[1,   300] loss: 0.004
[2,   100] loss: 0.003
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.003
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.003
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.003
[9,   300] loss: 0.002
[10,   100] loss: 0.002
[10,   200] loss: 0.001
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.167
[1,   200] loss: 0.006
[1,   300] loss: 0.005
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.002
[3,   200] loss: 0.002
[3,   300] loss: 0.002
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.002
[5,   100] loss: 0.002
[5,   200] loss: 0.002
[5,   300] loss: 0.002
[6,   100] loss: 0.002
[6,   200] loss: 0.002
[6,   300] loss: 0.002
[7,   100] loss: 0.001
[7,   200] loss: 0.002
[7,   300] loss: 0.003
[8,   100] loss: 0.002
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.002
[9,   300] loss: 0.002
[10,   100] loss: 0.002
[10,   200] loss: 0.001
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.153
[1,   200] loss: 0.006
[1,   300] loss: 0.004
[2,   100] loss: 0.002
[2,   200] loss: 0.003
[2,   300] loss: 0.002
[3,   100] loss: 0.003
[3,   200] loss: 0.001
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.001
[5,   200] loss: 0.003
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.002
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.002
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.180
[1,   200] loss: 0.004
[1,   300] loss: 0.003
[2,   100] loss: 0.003
[2,   200] loss: 0.003
[2,   300] loss: 0.002
[3,   100] loss: 0.002
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.002
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.002
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.082
[1,   200] loss: 0.004
[1,   300] loss: 0.004
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.003
[3,   100] loss: 0.001
[3,   200] loss: 0.002
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.002
[5,   100] loss: 0.001
[5,   200] loss: 0.002
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.003
[9,   200] loss: 0.002
[9,   300] loss: 0.001
[10,   100] loss: 0.003
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.063
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.002
[3,   100] loss: 0.002
[3,   200] loss: 0.002
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.002
[5,   100] loss: 0.001
[5,   200] loss: 0.002
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.002
[8,   100] loss: 0.002
[8,   200] loss: 0.002
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.069
[1,   200] loss: 0.007
[1,   300] loss: 0.003
[2,   100] loss: 0.003
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.002
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.002
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.080
[1,   200] loss: 0.005
[1,   300] loss: 0.003
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.001
[5,   100] loss: 0.003
[5,   200] loss: 0.002
[5,   300] loss: 0.002
[6,   100] loss: 0.002
[6,   200] loss: 0.001
[6,   300] loss: 0.002
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.000
[8,   200] loss: 0.001
[8,   300] loss: 0.002
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.071
[1,   200] loss: 0.005
[1,   300] loss: 0.002
[2,   100] loss: 0.003
[2,   200] loss: 0.001
[2,   300] loss: 0.002
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.002
[4,   300] loss: 0.002
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.001
[7,   300] loss: 0.002
[8,   100] loss: 0.001
[8,   200] loss: 0.002
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.002
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.056
[1,   200] loss: 0.004
[1,   300] loss: 0.001
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.003
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.001
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.000
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.000
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.061
[1,   200] loss: 0.003
[1,   300] loss: 0.003
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.002
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.003
[4,   300] loss: 0.002
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.003
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.002
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.004918032786885246
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.072
[1,   200] loss: 0.003
[1,   300] loss: 0.002
[2,   100] loss: 0.002
[2,   200] loss: 0.002
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.002
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.002
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.002
[6,   200] loss: 0.002
[6,   300] loss: 0.002
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.2459016393442623
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.097
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.002
[7,   100] loss: 0.001
[7,   200] loss: 0.002
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.003
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.077
[1,   200] loss: 0.002
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.002
[2,   300] loss: 0.002
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.002
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.000
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.002
[10,   200] loss: 0.002
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.121
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.002
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.002
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.133
[1,   200] loss: 0.005
[1,   300] loss: 0.003
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.002
[5,   300] loss: 0.001
[6,   100] loss: 0.003
[6,   200] loss: 0.002
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.136
[1,   200] loss: 0.003
[1,   300] loss: 0.001
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.002
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.000
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.145
[1,   200] loss: 0.003
[1,   300] loss: 0.001
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.003
[4,   200] loss: 0.003
[4,   300] loss: 0.001
[5,   100] loss: 0.002
[5,   200] loss: 0.001
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.000
[6,   300] loss: 0.001
[7,   100] loss: 0.003
[7,   200] loss: 0.002
[7,   300] loss: 0.001
[8,   100] loss: 0.002
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.002
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.228
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.000
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.186
[1,   200] loss: 0.003
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.002
[2,   300] loss: 0.001
[3,   100] loss: 0.002
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.000
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.000
[7,   100] loss: 0.004
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.000
[9,   100] loss: 0.000
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.167
[1,   200] loss: 0.005
[1,   300] loss: 0.001
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.002
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.002
[6,   200] loss: 0.002
[6,   300] loss: 0.000
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.000
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.175
[1,   200] loss: 0.002
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.009
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.000
[5,   200] loss: 0.002
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.000
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.002
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.000
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.182
[1,   200] loss: 0.003
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.000
[5,   200] loss: 0.000
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.000
[7,   300] loss: 0.000
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.153
[1,   200] loss: 0.003
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.003
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.000
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.000
[6,   200] loss: 0.001
[6,   300] loss: 0.003
[7,   100] loss: 0.001
[7,   200] loss: 0.000
[7,   300] loss: 0.001
[8,   100] loss: 0.000
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.004
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.144
[1,   200] loss: 0.007
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.000
[4,   200] loss: 0.000
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.000
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.114
[1,   200] loss: 0.003
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.002
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.002
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.002
[9,   100] loss: 0.000
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.095
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.003
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.000
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.002
[7,   200] loss: 0.000
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.003
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.126
[1,   200] loss: 0.004
[1,   300] loss: 0.004
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.000
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.000
[5,   300] loss: 0.000
[6,   100] loss: 0.002
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.000
[7,   300] loss: 0.003
[8,   100] loss: 0.001
[8,   200] loss: 0.001
[8,   300] loss: 0.000
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.195
[1,   200] loss: 0.003
[1,   300] loss: 0.004
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.000
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.000
[5,   200] loss: 0.001
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.000
[6,   300] loss: 0.000
[7,   100] loss: 0.003
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.002
[8,   200] loss: 0.000
[8,   300] loss: 0.002
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.185
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.000
[3,   300] loss: 0.000
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.000
[6,   100] loss: 0.003
[6,   200] loss: 0.002
[6,   300] loss: 0.000
[7,   100] loss: 0.001
[7,   200] loss: 0.001
[7,   300] loss: 0.001
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.000
[9,   100] loss: 0.001
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.195
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.003
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.000
[5,   300] loss: 0.001
[6,   100] loss: 0.000
[6,   200] loss: 0.000
[6,   300] loss: 0.000
[7,   100] loss: 0.001
[7,   200] loss: 0.000
[7,   300] loss: 0.000
[8,   100] loss: 0.000
[8,   200] loss: 0.001
[8,   300] loss: 0.000
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.187
[1,   200] loss: 0.005
[1,   300] loss: 0.003
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.001
[3,   200] loss: 0.000
[3,   300] loss: 0.000
[4,   100] loss: 0.000
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.001
[5,   200] loss: 0.001
[5,   300] loss: 0.000
[6,   100] loss: 0.000
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.000
[7,   300] loss: 0.000
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.137
[1,   200] loss: 0.004
[1,   300] loss: 0.001
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.002
[3,   200] loss: 0.001
[3,   300] loss: 0.000
[4,   100] loss: 0.003
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.000
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.002
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.002
[7,   300] loss: 0.001
[8,   100] loss: 0.000
[8,   200] loss: 0.000
[8,   300] loss: 0.000
[9,   100] loss: 0.000
[9,   200] loss: 0.000
[9,   300] loss: 0.001
[10,   100] loss: 0.000
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.129
[1,   200] loss: 0.003
[1,   300] loss: 0.001
[2,   100] loss: 0.001
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.000
[3,   300] loss: 0.001
[4,   100] loss: 0.002
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.001
[5,   200] loss: 0.000
[5,   300] loss: 0.000
[6,   100] loss: 0.001
[6,   200] loss: 0.000
[6,   300] loss: 0.001
[7,   100] loss: 0.001
[7,   200] loss: 0.000
[7,   300] loss: 0.001
[8,   100] loss: 0.000
[8,   200] loss: 0.001
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.001
[10,   100] loss: 0.002
[10,   200] loss: 0.002
[10,   300] loss: 0.002
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.116
[1,   200] loss: 0.004
[1,   300] loss: 0.001
[2,   100] loss: 0.000
[2,   200] loss: 0.001
[2,   300] loss: 0.001
[3,   100] loss: 0.000
[3,   200] loss: 0.001
[3,   300] loss: 0.001
[4,   100] loss: 0.001
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.003
[5,   200] loss: 0.002
[5,   300] loss: 0.001
[6,   100] loss: 0.000
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.000
[7,   300] loss: 0.000
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.001
[9,   200] loss: 0.001
[9,   300] loss: 0.000
[10,   100] loss: 0.006
[10,   200] loss: 0.003
[10,   300] loss: 0.001
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.156
[1,   200] loss: 0.004
[1,   300] loss: 0.002
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.000
[3,   100] loss: 0.001
[3,   200] loss: 0.000
[3,   300] loss: 0.000
[4,   100] loss: 0.000
[4,   200] loss: 0.000
[4,   300] loss: 0.000
[5,   100] loss: 0.003
[5,   200] loss: 0.001
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.000
[6,   300] loss: 0.000
[7,   100] loss: 0.001
[7,   200] loss: 0.002
[7,   300] loss: 0.000
[8,   100] loss: 0.001
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.000
[9,   200] loss: 0.001
[9,   300] loss: 0.000
[10,   100] loss: 0.001
[10,   200] loss: 0.001
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
Training 10 epoch(s) w/ 382 batches each
[1,   100] loss: 0.141
[1,   200] loss: 0.003
[1,   300] loss: 0.005
[2,   100] loss: 0.002
[2,   200] loss: 0.001
[2,   300] loss: 0.000
[3,   100] loss: 0.002
[3,   200] loss: 0.000
[3,   300] loss: 0.001
[4,   100] loss: 0.000
[4,   200] loss: 0.001
[4,   300] loss: 0.001
[5,   100] loss: 0.000
[5,   200] loss: 0.000
[5,   300] loss: 0.001
[6,   100] loss: 0.001
[6,   200] loss: 0.001
[6,   300] loss: 0.001
[7,   100] loss: 0.000
[7,   200] loss: 0.000
[7,   300] loss: 0.000
[8,   100] loss: 0.000
[8,   200] loss: 0.000
[8,   300] loss: 0.001
[9,   100] loss: 0.000
[9,   200] loss: 0.001
[9,   300] loss: 0.000
[10,   100] loss: 0.000
[10,   200] loss: 0.000
[10,   300] loss: 0.000
<class 'float'> 0.0
<class 'dict'>
