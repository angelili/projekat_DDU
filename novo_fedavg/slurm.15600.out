Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.030
[1,   200] loss: 0.006
[1,   300] loss: 0.003
<class 'float'> 0.5418803418803418
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.021
[1,   200] loss: 0.004
[1,   300] loss: 0.002
<class 'float'> 0.7162393162393162
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.016
[1,   200] loss: 0.004
[1,   300] loss: 0.003
<class 'float'> 0.7743589743589744
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.013
[1,   200] loss: 0.004
[1,   300] loss: 0.002
<class 'float'> 0.7008547008547008
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.012
[1,   200] loss: 0.003
[1,   300] loss: 0.003
<class 'float'> 0.7521367521367521
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.011
[1,   200] loss: 0.003
[1,   300] loss: 0.002
<class 'float'> 0.8358974358974359
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.009
[1,   200] loss: 0.002
[1,   300] loss: 0.002
<class 'float'> 0.8427350427350427
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.007
[1,   200] loss: 0.002
[1,   300] loss: 0.002
<class 'float'> 0.7025641025641025
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.008
[1,   200] loss: 0.002
[1,   300] loss: 0.002
<class 'float'> 0.67008547008547
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.006
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.6649572649572649
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.005
[1,   200] loss: 0.002
[1,   300] loss: 0.002
<class 'float'> 0.8615384615384616
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.005
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.47692307692307695
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.005
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.8923076923076924
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.005
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.611965811965812
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.004
[1,   200] loss: 0.001
[1,   300] loss: 0.002
<class 'float'> 0.6905982905982906
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.004
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.5282051282051282
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.7401709401709402
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.5675213675213675
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.004
[1,   200] loss: 0.002
[1,   300] loss: 0.001
<class 'float'> 0.8376068376068376
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.002
[1,   300] loss: 0.002
<class 'float'> 0.4188034188034188
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.004
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.9333333333333333
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.3162393162393162
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.9623931623931624
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.5726495726495726
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.7726495726495727
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.8051282051282052
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.5675213675213675
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.7350427350427351
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.611965811965812
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.7213675213675214
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.7760683760683761
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.7196581196581197
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.000
[1,   300] loss: 0.001
<class 'float'> 0.7606837606837606
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.8273504273504273
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.6393162393162393
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.003
<class 'float'> 0.8051282051282052
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.6427350427350428
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.582905982905983
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.8512820512820513
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.002
[1,   200] loss: 0.003
[1,   300] loss: 0.000
<class 'float'> 0.4735042735042735
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.003
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.9538461538461539
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.4581196581196581
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.000
[1,   300] loss: 0.001
<class 'float'> 0.947008547008547
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.5521367521367522
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.000
[1,   300] loss: 0.001
<class 'float'> 0.8632478632478633
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.7230769230769231
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.000
[1,   300] loss: 0.001
<class 'float'> 0.6478632478632479
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.000
<class 'float'> 0.8905982905982905
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.000
[1,   300] loss: 0.000
<class 'float'> 0.37435897435897436
<class 'dict'>
Training 1 epoch(s) w/ 366 batches each
[1,   100] loss: 0.001
[1,   200] loss: 0.001
[1,   300] loss: 0.001
<class 'float'> 0.9264957264957265
<class 'dict'>
